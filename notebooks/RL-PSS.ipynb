{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "LAMBDA = 0.95\n",
    "GAMMA = 0.99\n",
    "\n",
    "ACTOR_LR = 8e-4\n",
    "CRITIC_LR = 4e-4\n",
    "\n",
    "CLIP = 0.2\n",
    "ENTROPY_COEF = 2e-2\n",
    "BATCHES_PER_UPDATE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EPISODES_PER_UPDATE = 20\n",
    "ITERATIONS = 200\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "eng.quit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(eng.isprime(37))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "state = eng.default_state_PSS()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 163.74731183052063 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for _ in range(20):\n",
    "    state = eng.sim_step(state, 1.)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "MatlabExecutionError",
     "evalue": "Initial state vector \"X0\" must be a real vector of length 1\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMatlabExecutionError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-8596b3b2aca3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mstart_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meng\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msim_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"--- %s seconds ---\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/site-packages/matlab/engine/matlabengine.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mFutureResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_stdout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_stderr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 70\u001B[0;31m             return FutureResult(self._engine(), future, nargs, _stdout,\n\u001B[0m\u001B[1;32m     71\u001B[0m                                 _stderr, feval=True).result()\n\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/site-packages/matlab/engine/futureresult.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     65\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpythonengine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetMessage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'TimeoutCannotBeNegative'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__future\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcancel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/site-packages/matlab/engine/fevalfuture.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     80\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpythonengine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetMessage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'MatlabFunctionTimeout'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpythonengine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetFEvalResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_future\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nargout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_out\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_err\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     83\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_retrieved\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mMatlabExecutionError\u001B[0m: Initial state vector \"X0\" must be a real vector of length 1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for _ in range(100):\n",
    "    state = eng.sim_step(state, 1.)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 60])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.tensor(np.random.rand(1, 4, 60), dtype=torch.float)\n",
    "sample.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "class OSBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernels=[1, 3, 5, 7, 11]):\n",
    "        super().__init__()\n",
    "        assert out_channels % 2 == 0, \"Numnber of out channels should be odd!\"\n",
    "        self.kernels = kernels\n",
    "        self.convs1 = nn.ModuleList([nn.Conv1d(in_channels=in_channels,\n",
    "                                               out_channels=4, kernel_size=kernel,\n",
    "                                               padding=kernel // 2, padding_mode='reflect')\n",
    "                                     for kernel in kernels])\n",
    "        self.convs2 = nn.ModuleList([nn.Conv1d(in_channels=4 * len(kernels),\n",
    "                                               out_channels=4,\n",
    "                                               kernel_size=kernel,\n",
    "                                               padding=kernel // 2, padding_mode='reflect')\n",
    "                                     for kernel in kernels])\n",
    "        self.batchnorm1 = nn.Sequential(nn.BatchNorm1d(4 * len(kernels)), nn.ReLU())\n",
    "        self.batchnorm2 = nn.Sequential(nn.BatchNorm1d(4 * len(kernels)), nn.ReLU())\n",
    "        self.convs3 = nn.ModuleList([nn.Conv1d(in_channels=4 * len(kernels),\n",
    "                                                out_channels=out_channels // 2,\n",
    "                                                kernel_size=kernel,\n",
    "                                                padding=kernel // 2, padding_mode='reflect')\n",
    "                                      for kernel in [1, 3]])\n",
    "        self.batchnorm3 = nn.Sequential(nn.BatchNorm1d(out_channels), nn.ReLU())\n",
    "\n",
    "    def forward(self, state):\n",
    "        intermediate = torch.concat([l(state) for l in self.convs1], dim=-2)\n",
    "        intermediate = self.batchnorm1(intermediate)\n",
    "        intermediate = torch.concat([l(intermediate) for l in self.convs2], dim=-2)\n",
    "        intermediate = self.batchnorm2(intermediate)\n",
    "        intermediate = torch.concat([l(intermediate) for l in self.convs3], dim=-2)\n",
    "        intermediate  =self.batchnorm3(intermediate)\n",
    "        return intermediate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "blk = OSBlock(4, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 60])"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = blk(sample)\n",
    "res.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 60])"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OSBlock(8,4)(res).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "2884"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(blk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "8439"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor = Actor(5, [1, 1, 1, 1,1])\n",
    "count_parameters(actor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 10])"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.AdaptiveAvgPool1d(10)\n",
    "pool(res).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 60])"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def compute_lambda_returns_and_gae(trajectory):\n",
    "    lambda_returns = []\n",
    "    gae = []\n",
    "    last_lr = 0.\n",
    "    last_v = 0.\n",
    "    for _, _, r, _, v in reversed(trajectory):\n",
    "        ret = r + GAMMA * (last_v * (1 - LAMBDA) + last_lr * LAMBDA)\n",
    "        last_lr = ret\n",
    "        last_v = v\n",
    "        lambda_returns.append(last_lr)\n",
    "        gae.append(last_lr - v)\n",
    "\n",
    "    # Each transition contains state, action, old action probability, value estimation and advantage estimation\n",
    "    return [(s, a, p, v, adv) for (s, a, _, p, _), v, adv in zip(trajectory, reversed(lambda_returns), reversed(gae))]\n",
    "\n",
    "\n",
    "class OSBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernels=[1, 3, 5, 7, 11]):\n",
    "        super().__init__()\n",
    "        assert out_channels % 2 == 0, \"Numnber of out channels should be odd!\"\n",
    "        self.kernels = kernels\n",
    "        self.convs1 = nn.ModuleList([nn.Conv1d(in_channels=in_channels,\n",
    "                                               out_channels=4, kernel_size=kernel,\n",
    "                                               padding=kernel // 2)\n",
    "                                     for kernel in kernels])\n",
    "        self.convs2 = nn.ModuleList([nn.Conv1d(in_channels=4 * len(kernels),\n",
    "                                               out_channels=4,\n",
    "                                               kernel_size=kernel,\n",
    "                                               padding=kernel // 2)\n",
    "                                     for kernel in kernels])\n",
    "        self.batchnorm1 = nn.Sequential(nn.BatchNorm1d(4 * len(kernels)), nn.ReLU())\n",
    "        self.batchnorm2 = nn.Sequential(nn.BatchNorm1d(4 * len(kernels)), nn.ReLU())\n",
    "        self.convs3 = nn.ModuleList([nn.Conv1d(in_channels=4 * len(kernels),\n",
    "                                               out_channels=out_channels // 2,\n",
    "                                               kernel_size=kernel,\n",
    "                                               padding=kernel // 2)\n",
    "                                     for kernel in [1, 3]])\n",
    "        self.batchnorm3 = nn.Sequential(nn.BatchNorm1d(out_channels), nn.ReLU())\n",
    "\n",
    "    def forward(self, state):\n",
    "        intermediate = torch.concat([l(state) for l in self.convs1], dim=-2)\n",
    "        intermediate = self.batchnorm1(intermediate)\n",
    "        intermediate = torch.concat([l(intermediate) for l in self.convs2], dim=-2)\n",
    "        intermediate = self.batchnorm2(intermediate)\n",
    "        intermediate = torch.concat([l(intermediate) for l in self.convs3], dim=-2)\n",
    "        intermediate = self.batchnorm3(intermediate)\n",
    "        return intermediate\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_size):\n",
    "        super().__init__()\n",
    "        self.enc1 = OSBlock(in_channels, in_channels)\n",
    "        self.enc2 = OSBlock(in_channels, in_channels)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_size * in_channels, hidden_size * in_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.enc1(state)\n",
    "        x = self.enc2(x + state)\n",
    "        x = self.linear(x.view(x.shape[0], -1))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, action_dim, action_scaler):\n",
    "        super().__init__()\n",
    "        # Advice: use same log_sigma for all states to improve stability\n",
    "        # You can do this by defining log_sigma as nn.Parameter(torch.zeros(...))\n",
    "        self.encoder = Encoder(4, 60)\n",
    "        self.mean = torch.nn.Sequential(\n",
    "            torch.nn.Linear(240, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, action_dim),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        # self.sigma = nn.Sequential(\n",
    "        #     nn.Linear(256, action_dim),\n",
    "        #     nn.ELU()\n",
    "        # )\n",
    "        self.action_scaler = torch.tensor(action_scaler, dtype=torch.float32)\n",
    "        self.sigma = nn.Parameter(torch.zeros(action_dim))\n",
    "\n",
    "    def compute_proba(self, state, action):\n",
    "        # Returns probability of action according to current policy and distribution of actions\n",
    "        _, pa, distribution = self.act(state)\n",
    "        proba = distribution.log_prob(action).sum(-1)\n",
    "        return proba, distribution\n",
    "\n",
    "    def act(self, state):\n",
    "        # Returns an action (with tanh), not-transformed action (without tanh) and distribution of non-transformed actions\n",
    "        # Remember: agent is not deterministic, sample actions from distribution (e.g. Gaussian)\n",
    "        latent = self.encoder(state)\n",
    "        mean = self.mean(latent)\n",
    "        # sigma = torch.exp(-self.sigma(latent))\n",
    "        sigma = torch.exp(self.sigma)\n",
    "        distribution = Normal(mean, sigma)\n",
    "        action = distribution.sample()\n",
    "        tanh_action = torch.sigmoid(action) * self.action_scaler\n",
    "        # tanh_action = torch.sigmoid(action)\n",
    "        return tanh_action, action, distribution\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(4, 60)\n",
    "        self.mean = torch.nn.Sequential(\n",
    "            torch.nn.Linear(240, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def get_value(self, state):\n",
    "        latent = self.encoder(state)\n",
    "        return self.mean(latent)\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, action_scaler, action_dim, device='cpu'):\n",
    "        self.device = device\n",
    "        self.actor = Actor(action_dim, action_scaler).to(self.device)\n",
    "        self.critic = Critic().to(self.device)\n",
    "        self.actor_optim = Adam(self.actor.parameters(), ACTOR_LR, amsgrad=True)\n",
    "        self.critic_optim = Adam(self.critic.parameters(), CRITIC_LR, amsgrad=True)\n",
    "\n",
    "        # self.actor_scheduler = torch.optim.lr_scheduler.CyclicLR(self.actor_optim, base_lr=1e-3,\n",
    "        #                                                          max_lr=1e-2, step_size_up=100, mode='triangular2',\n",
    "        #                                                          cycle_momentum=False)\n",
    "        # self.critic_scheduler = torch.optim.lr_scheduler.CyclicLR(self.critic_optim, base_lr=5e-4,\n",
    "        #                                                           max_lr=5e-3, step_size_up=100, mode='triangular2',\n",
    "        #                                                           cycle_momentum=False)\n",
    "\n",
    "    def update(self, trajectories):\n",
    "        transitions = [t for traj in trajectories for t in traj]  # Turn a list of trajectories into list of transitions\n",
    "        state, action, old_prob, target_value, advantage = zip(*transitions)\n",
    "        state = torch.FloatTensor(np.array(state)).to(self.device)\n",
    "        action = torch.FloatTensor(np.array(action)).to(self.device)\n",
    "        old_prob = torch.FloatTensor(np.array(old_prob)).to(self.device)\n",
    "        target_value = torch.FloatTensor(np.array(target_value)).to(self.device)\n",
    "        advantage = np.array(advantage)\n",
    "        advantage = torch.FloatTensor((advantage - advantage.mean()) / (advantage.std() + 1e-8)).to(self.device)\n",
    "\n",
    "        actor_loss_ls = []\n",
    "        critic_loss_ls = []\n",
    "\n",
    "        for _ in range(BATCHES_PER_UPDATE):\n",
    "            # idx = np.random.randint(0, len(transitions), BATCH_SIZE)  # Choose random batch\n",
    "            idx = torch.randint(0, len(transitions), (BATCH_SIZE,)).to(self.device)\n",
    "            s = state[idx]\n",
    "            a = action[idx]\n",
    "            op = old_prob[idx]  # Probability of the action in state s.t. old policy\n",
    "            v = target_value[idx]  # Estimated by lambda-returns\n",
    "            adv = advantage[idx]  # Estimated by generalized advantage estimation\n",
    "\n",
    "            # Update actor here\n",
    "            log_prob, distribution = self.actor.compute_proba(s, a)\n",
    "            ratio = torch.exp(log_prob - op)\n",
    "            surr1 = ratio * adv\n",
    "            surr2 = torch.clamp(ratio, 1 - CLIP, 1 + CLIP) * adv\n",
    "            actor_loss = (-torch.min(surr1, surr2)).mean() - ENTROPY_COEF * distribution.entropy().mean()\n",
    "            actor_loss_ls.append(actor_loss.item())\n",
    "            self.actor_optim.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optim.step()\n",
    "\n",
    "            # Update critic here\n",
    "            critic_value = self.critic.get_value(s)\n",
    "            critic_loss = nn.MSELoss()(torch.squeeze(critic_value), v)\n",
    "            critic_loss_ls.append(critic_loss.item())\n",
    "            self.critic_optim.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optim.step()\n",
    "        # self.critic_scheduler.step()\n",
    "        # self.actor_scheduler.step()\n",
    "        return np.mean(actor_loss_ls), np.mean(critic_loss_ls)\n",
    "\n",
    "    def get_value(self, state):\n",
    "        with torch.no_grad():\n",
    "            state.to(self.device)\n",
    "            value = self.critic.get_value(state)\n",
    "        return value.item()\n",
    "\n",
    "    def act(self, state):\n",
    "        with torch.no_grad():\n",
    "            state.to(self.device)\n",
    "            action, pure_action, distr = self.actor.act(state)\n",
    "            log_prob = distr.log_prob(pure_action).sum(-1)\n",
    "            # log_prob = distr.log_prob(pure_action)\n",
    "        return action, pure_action, log_prob\n",
    "\n",
    "    def save(self, name=\"agent.pkl\", folder=\"\"):\n",
    "        torch.save(self.actor.state_dict(), path.join(folder, name))\n",
    "        torch.save(self.critic.state_dict(), path.join(folder, 'critic_' + name))\n",
    "\n",
    "    def load(self, name=\"agent.pkl\", folder=\"\"):\n",
    "        self.actor.load_state_dict(torch.load(path.join(folder, name)))\n",
    "        self.critic.load_state_dict(torch.load(path.join(folder, 'critic_' + name)))\n",
    "        self.actor.eval()\n",
    "        self.critic.eval()\n",
    "        self.actor.to(self.device)\n",
    "        self.critic.to(self.device)\n",
    "\n",
    "    def perform(self):\n",
    "        self.actor.to('cpu')\n",
    "        self.critic.to('cpu')\n",
    "        self.actor.eval()\n",
    "        self.critic.eval()\n",
    "\n",
    "    def train_(self):\n",
    "        self.actor.to(self.device)\n",
    "        self.critic.to(self.device)\n",
    "        self.actor.train()\n",
    "        self.critic.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "ppo = PPO(action_dim=5, action_scaler=[1, 1, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.6797, 0.2996, 0.8412, 0.3858, 0.8816]]),\n tensor([[ 0.7526, -0.8494,  1.6669, -0.4649,  2.0077]]),\n tensor([-8.6462]))"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.act(sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}